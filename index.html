<!DOCTYPE HTML>
<html>
    <head>
        <title>Towards Precise Model-free Robotic Grasping with Sim-to-Real Transfer Learning</title>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=1000">
        <link rel="stylesheet" href="https://use.typekit.net/quv7bsd.css"> <!-- fonts -->
        <link rel="stylesheet" href="style.css" />
        <script>
          (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
          (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
          })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
          ga('create', 'UA-89797207-1', 'auto');
          ga('send', 'pageview');
        </script>
    </head>
    <body id="body">
        <div id="main"> 
            <header id="header">
            </header>
            <!-- style="padding-bottom:1em" -->
            <div id="profile">
                <!-- <img src="images/profile.jpg"> -->
                <div id="profile-desc">
                    <div id="profile-name"><b>Towards Precise Model-free Robotic Grasping with Sim-to-Real Transfer Learning</b>
                        <p><br>2022 IEEE International Conference on Robotics and Biomimetics (IEEE ROBIO 2022)</p>
                    </div>
                    <p>
                        <b>Abstract</b>. Precise robotic grasping of several novel objects is
                        a huge challenge in manufacturing, automation, and logistics.
                        Most of the current methods for model-free grasping are
                        disadvantaged by the sparse data in grasping datasets and by
                        errors in sensor data and contact models. This study combines
                        data generation and sim-to-real transfer learning in a grasping
                        framework that reduces the sim-to-real gap and enables precise
                        and reliable model-free grasping. A large-scale robotic grasping
                        dataset with dense grasp labels is generated using domain
                        randomization methods and a novel data augmentation method
                        for deep learning-based robotic grasping to solve data sparse
                        problem. We present an end-to-end robotic grasping network
                        with a grasp optimizer. The grasp policies are trained with
                        sim-to-real transfer learning. The presented results suggest that
                        our grasping framework reduces the uncertainties in grasping
                        datasets, sensor data, and contact models. In physical robotic
                        experiments, our grasping framework grasped single known
                        objects and novel complex-shaped household objects with a
                        success rate of 90.91%. In a complex scenario with multi-objects
                        robotic grasping, the success rate was 85.71%. The proposed
                        grasping framework outperformed two state-of-the-art methods
                        in both known and unknown object robotic grasping.
                    </p>
                </div>
                <div style="clear: both;"></div>
            </div>
            <div class="section recent-work">
                <!-- <h1>Highlights</h1> -->
                <div class="highlight-proj">
                    <!-- <a href="http://arc.cs.princeton.edu/"> --><video width="100%" playsinline="" muted="" autoplay="" loop="">
                        <source src="images/01_single_obj_grasp.mp4" type="video/mp4">
                    </video><!-- </a> --><p>Single Object Grasping</p>
                </div>
                <div class="highlight-proj">
                    <!-- <a href="http://tossingbot.cs.princeton.edu/"> --><video width="100%" playsinline="" muted="" autoplay="" loop="">
                        <source src="images/02_multi_obj_grasp_youtube.mp4" type="video/mp4">
                    </video><!-- </a> --><p>Multi-Object Grasping</p>
                </div>
                <div class="highlight-proj">
                    <!-- <a href="http://tossingbot.cs.princeton.edu/"> --><video width="100%" playsinline="" muted="" autoplay="" loop="">
                        <source src="images/03_cable_grasp.mp4" type="video/mp4">
                    </video><!-- </a> --><p>Cable Grasping</p>
                </div>
            </div>
            <div class="divider"></div>  
            <div class="section paper">
                <h1>Paper</h1>
                    <font color="4e79a7">&#9733; Best Conference Paper or ROBOTICA Best Paper Award Finalist, IEEE ROBIO 2022 &#9733;</font></p><br>
            </div>
            <div class="divider"></div>
            <div class="section bibtex">
                <h1>Bibtex</h1>
                <div class="code">@article{code,<br>
                &nbsp;&nbsp;&nbsp;&nbsp;title={Title},<br>
                &nbsp;&nbsp;&nbsp;&nbsp;author={authors},<br>
                &nbsp;&nbsp;&nbsp;&nbsp;journal={journal},<br>
                &nbsp;&nbsp;&nbsp;&nbsp;year={2022}<br>
                }</div>
            </div>    
            <div class="divider"></div>
            
            <br><br><br><br><br><br><br><br><br><br>
            <div class="divider"></div>
        </div>
    </body>
</html>